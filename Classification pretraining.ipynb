{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f77f100d-9746-4256-94e1-48a9431f3824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/MedClip/src\n"
     ]
    }
   ],
   "source": [
    "cd src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7248881-e418-4aab-abc1-9d97287f80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from preprocess import pipelines\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23648009-0d04-4bd1-a683-61ef94b18bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/intermediate/inter_chexpert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e63c8d3-8731-4c84-b668-9a745dc7d834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making input pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 00:44:53.369795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 00:44:53.424050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 00:44:53.424937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 00:44:53.426682: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-08 00:44:53.427983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 00:44:53.428924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 00:44:53.429851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 00:44:53.994521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 00:44:53.995344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 00:44:53.996214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 00:44:53.997084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n"
     ]
    }
   ],
   "source": [
    "data_pipeline=pipelines.make_pipeline('../data/intermediate/inter_chexpert.csv',downscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9530ed8-dd5e-4fcc-992b-78676d58bf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CLIP': {'train': <ZipDataset element_spec=({'image': TensorSpec(shape=(299, 299, 3), dtype=tf.float32, name=None), 'text': TensorSpec(shape=(), dtype=tf.string, name=None)},)>,\n",
       "  'val': <ZipDataset element_spec=({'image': TensorSpec(shape=(299, 299, 3), dtype=tf.float32, name=None), 'text': TensorSpec(shape=(), dtype=tf.string, name=None)},)>,\n",
       "  'test': <ZipDataset element_spec=({'image': TensorSpec(shape=(299, 299, 3), dtype=tf.float32, name=None), 'text': TensorSpec(shape=(), dtype=tf.string, name=None)},)>},\n",
       " 'captioning': {'train': <ZipDataset element_spec=(TensorSpec(shape=(299, 299, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>,\n",
       "  'val': <ZipDataset element_spec=(TensorSpec(shape=(299, 299, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>,\n",
       "  'test': <ZipDataset element_spec=(TensorSpec(shape=(299, 299, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>},\n",
       " 'labeling': {'train': <ZipDataset element_spec=(TensorSpec(shape=(299, 299, 3), dtype=tf.float32, name=None), TensorSpec(shape=(41,), dtype=tf.int64, name=None))>,\n",
       "  'val': <ZipDataset element_spec=(TensorSpec(shape=(299, 299, 3), dtype=tf.float32, name=None), TensorSpec(shape=(41,), dtype=tf.int64, name=None))>,\n",
       "  'test': <ZipDataset element_spec=(TensorSpec(shape=(299, 299, 3), dtype=tf.float32, name=None), TensorSpec(shape=(41,), dtype=tf.int64, name=None))>}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f5d408-bc71-4157-818c-e30998bf3ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making input pipeline\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 299, 299, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 299, 299, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 299, 299, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 10, 10, 2048)      23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 204800)            0         \n",
      "                                                                 \n",
      " encoding_layer (Dense)      (None, 128)               26214528  \n",
      "                                                                 \n",
      " classification_layer (Dense  (None, 41)               5289      \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,807,529\n",
      "Trainable params: 26,219,817\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#High level args\n",
    "data_pipeline=pipelines.make_pipeline('../data/intermediate/inter_chexpert.csv',downscale=False)\n",
    "embedding_size = 128\n",
    "dataset = data_pipeline['labeling']\n",
    "\n",
    "train_backbone= False\n",
    "log_dir='../model_logs/pretraining/classification/'+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_filepath='../model_checkpoints/pretraining/classification/'+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Inside function\n",
    "\n",
    "\n",
    "\n",
    "train_data=data_pipeline['labeling']['train'].batch(128)\n",
    "val_data=data_pipeline['labeling']['val'].batch(128)\n",
    "\n",
    "input_shape = train_data.element_spec[0].shape.as_list()[1:]\n",
    "n_classes = int(train_data.element_spec[1].shape.as_list()[1])\n",
    "\n",
    "\n",
    "inputs=tf.keras.Input(shape=input_shape, name='input')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "backbone= tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if (train_backbone==False):\n",
    "    for layer in backbone.layers:\n",
    "        layer.trainable=False\n",
    "x = tf.keras.applications.resnet50.preprocess_input(inputs) # preprocess data\n",
    "x = backbone(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(embedding_size,activation=None,name='encoding_layer')(x)\n",
    "x = tf.keras.layers.Dense(n_classes,activation='sigmoid',name='classification_layer')(x)\n",
    "\n",
    "model=tf.keras.Model(inputs=inputs,outputs=x)\n",
    "\n",
    "\n",
    "# Define callbacks\n",
    "tf_callback=tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,\n",
    "        write_graph=True,\n",
    "        write_images=False,\n",
    "        write_steps_per_second=False,\n",
    "        update_freq='epoch',\n",
    "        profile_batch=0,\n",
    "        embeddings_freq=0,\n",
    "        embeddings_metadata=None,\n",
    "    )\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy','AUC','Precision','Recall']\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd3378a-0085-4296-aca1-d120a0c575a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 00:45:04.534437: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 212/1224 [====>.........................] - ETA: 39:18 - loss: 5.0637 - accuracy: 0.7213 - auc: 0.8336 - precision: 0.7505 - recall: 0.7506"
     ]
    }
   ],
   "source": [
    "model.fit(train_data,epochs=20,callbacks=[tf_callback],validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be9a00-2c2b-41e9-a771-cfa465630437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c87909f-b33b-4f7b-beb0-2a2a3fecadd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ../model_logs/pretraining/"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "venv",
   "name": "tf2-gpu.2-8.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m94"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
