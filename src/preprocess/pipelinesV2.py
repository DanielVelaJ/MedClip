# -*- coding: utf-8 -*-
"""
Created on Tue Jun 28 14:03:11 2022

@author: Daniel Vela Jarquin

This module contains the functions to generate pipelines ready for modeling.
it requires the following to work:
    1. The raw folder has the unzipped datasets. This is done by the script
        download_data.py
    2. The prepared datasets are ready. These are generated by the script
        prepare_data.py

"""
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds
import numpy as np

def decode_and_resize(img_path,image_size):
    """Recieves an image path, decodes and rescales it. """
    img = tf.io.read_file(img_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, image_size)
    img = tf.image.convert_image_dtype(img, tf.float32)
    return img

def to_dict(image, text):
    """ To be called on dataset.map to get a dictionary"""
    return {'image': image, 'text': text}

def build_tf_dataset(df_subset,image_size):
    """Build captioning tensorflow dataset from dataframe
    
    The captioning tensorflow dataset returns dictionaries
    containing "images" and "text" keys.
    
    Args: 
        df_subset(pandas df): The dataframe from which to extract
            imagepaths and captions. It must contain the columns
            "Full_Caption" and "Path"
    Returns
        captioning_tf_dataset(tf dataset): Captioning tensorflow dataset. 
    """
    # Build images tf dataset
    images_tf_dataset = tf.data.Dataset.from_tensor_slices(df_subset['Path'])\
                            .map(lambda x: decode_and_resize(x,image_size),num_parallel_calls=tf.data.AUTOTUNE)

    # Build captions tf_dataset
    captions_tf_dataset = tf.data.Dataset\
                              .from_tensor_slices(df_subset['Full_Caption'].astype(str))

    # Zip df_subset images and captions datasets into a captioning dataset. 
    captioning_tf_dataset = tf.data.Dataset.zip(
                                                    (images_tf_dataset, 
                                                     captions_tf_dataset.map(lambda x:tf.expand_dims(x,axis=0)))
                                                  ).map(to_dict)
    return captioning_tf_dataset

def build_pipeline(inter_dataset_path='../data/intermediate/inter_medpix.csv',
                   image_size=(299, 299),
                   train_val_test_split=[0.70,0.15,0.15]):
    """ Build a captioining pipeline.
    
    Args:
        inter_dataset_path(str):path to the intermediate dataset. 
        image_size(tuple): size for image resizing. 
        train_val_test_split: the fraction of data to use for training
            validation and test sets.

    """
    df = pd.read_csv(inter_dataset_path) # Read csv
    df = df.sample(frac=1,random_state=1).reset_index() # shuffle df

    # Split into train validation and test splits------------------------------
    n=len(df) # Number of samples in the df
    train_n = int(train_val_test_split[0]*n) # Number of samples in training set
    val_n = int(train_val_test_split[1]*n)   # Number of samples in val set
    test_n = n-train_n-val_n                 # Number of samples in test set

    # Make sure there are no duplicates in the validation and test sets.
    # unless we are using the chexpert dataset which has many duplicates. 

    # If we are not using the chexpert dataset
    if 'chexpert' not in inter_dataset_path:

        uniques=df[~df.duplicated('Full_Caption')]   # unique values
        duplicated=df[df.duplicated('Full_Caption')] # duplicated values

        # If there are enough unique values to fill the validation and test sets:
        if len(uniques)>=(val_n+test_n):
            val_df=uniques[0:val_n]                  # Populate validation df
            test_df=uniques[val_n:val_n+test_n]      # Populate test df
            remaining_uniques=uniques[val_n+test_n:] # Unique samples not used so far
            # Concatenate remaining uniques with duplicates
            train_df=pd.concat([remaining_uniques,duplicated],axis=0)  
            train_df=train_df.sample(frac=1,random_state=1)\
                           .reset_index(drop=True)   # Shuffle train_df again. 
        else:
        # If there are not enough samples print error message
            print('not enough unique values to generate these many validation and test samples')
            exit()
    else:
    # If using the chexpert dataset populate despite duplicates 
        train_df=df[0:train_n]
        val_df=df[train_n:train_n+val_n]
        test_df=df[train_n+val_n:train_n+val_n+test_n]

    # Generate tensorflow datasets for training, validation and test sets.-------------
    train_captioning_tf_dataset = build_tf_dataset(train_df,image_size) # Generate training tensorflow dataset from training df
    val_captioning_tf_dataset = build_tf_dataset(val_df,image_size)     # Generate validation tensorflow dataset from validation df
    test_captioning_tf_dataset = build_tf_dataset(test_df,image_size)   # Generate test tensorflow dataset from test df

    pipeline = {'captioning':{
                                'train':train_captioning_tf_dataset,
                                'val':val_captioning_tf_dataset,
                                'test':test_captioning_tf_dataset,
                                'train_captions':train_df['Full_Caption'].astype(str).to_list()
                             }
                } 
    return pipeline
    
