{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2090a628-f6c0-45fc-959b-ca908299827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import imghdr\n",
    "import time\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e0f5154c-7526-4304-ab6f-10988be6884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Configure where to save the resulting dataset\n",
    "    save_path_dir = '../data/intermediate/'\n",
    "    os.makedirs(save_path_dir, exist_ok=True)\n",
    "    save_path = save_path_dir+'inter_medpix.csv'\n",
    "\n",
    "    # Read the raw df\n",
    "    path = '../data/raw/medpix/Dataset_MedPix_V1.xlsx'\n",
    "    df = pd.read_excel(path)\n",
    "\n",
    "    # Grab useful columns\n",
    "    # useful_cols=['ID','Plane',\n",
    "    #              'Core_Modality','Full_Modality',\n",
    "    #              'Findings','Case_Diagnosis','Location']\n",
    "    useful_cols=['Case_URL','ID','Plane',\n",
    "                 'Core_Modality','Full_Modality',\n",
    "                 'Caption','Case_Diagnosis','Location']\n",
    "    \n",
    "    df=df[useful_cols]\n",
    "\n",
    "    # Rename columns\n",
    "    renamings={'ID':'Path',\n",
    "               'Full_Modality':'Modality',\n",
    "              'Case_Diagnosis':'Impression',\n",
    "              'Location':'Anatomy'}\n",
    "    df.rename(columns=renamings,inplace=True)\n",
    "    # Now the dataframe contains columns \n",
    "    #['Path', 'Plane', 'Core_Modality', 'Modality', 'Caption', 'Impression',\n",
    "    # 'Anatomy']\n",
    "\n",
    "\n",
    "    # Drop rows with empty values\n",
    "    df = df.dropna() \n",
    "\n",
    "    # CLEANING ON THE \"PLANE\" COLUMN-------------------------\n",
    "    # Consolidating synonims into single types.\n",
    "    df.Plane.replace('Transverse','Axial',inplace=True)\n",
    "    df.Plane.replace('Lateral','Sagittal',inplace=True)\n",
    "    df.Plane.replace('Frontal','Coronal',inplace=True)\n",
    "\n",
    "    # Keep rows that have a plane values with a frequency higher than 100\n",
    "    valid_index=df.Plane.value_counts().index[df.Plane.value_counts()>100]\n",
    "    df=df.loc[df.Plane.isin(valid_index)]\n",
    "\n",
    "    # Drop whenever plane is equal to particular values.\n",
    "    df = df.loc[~df.Plane.isin(['NOS - Not specified', #\n",
    "                          'Other View (see caption)'])]\n",
    "\n",
    "    # CLEANING ON THE \"CORE_MODALITY\" COLUMN-------------------\n",
    "    # Consolidating synonims under the same concept.\n",
    "    df.Core_Modality.replace('US-D','US',inplace=True)\n",
    "    df.Core_Modality.replace('CTA','AN',inplace=True)\n",
    "    df.Core_Modality.replace('MRA','AN',inplace=True)\n",
    "    df.Core_Modality.replace('Histology','HE',inplace=True)\n",
    "    df.Core_Modality.replace('PET','PET/NM',inplace=True)\n",
    "    df.Core_Modality.replace('NM','PET/NM',inplace=True)\n",
    "    df.Core_Modality.replace('PET-CT','PET/NM',inplace=True)\n",
    "    df.Core_Modality.replace('MRS','MR',inplace=True)\n",
    "    \n",
    "    # Renaming interventional instances to INT\n",
    "    df.Core_Modality.replace('Interventional','INT',inplace=True) \n",
    "\n",
    "    # Keep rows that have a Core_Modality values with a frequency higher than 100\n",
    "    valid_index=df.Core_Modality.value_counts().index[df.Core_Modality.value_counts()>100]\n",
    "    df=df.loc[df.Core_Modality.isin(valid_index)]\n",
    "\n",
    "    # Drop whenever plane is equal to particular values.\n",
    "    df = df.loc[~df.Core_Modality.isin(['NOS'])]\n",
    "\n",
    "    # CLEANING ON \"FINDINGS\" COLUMN------------------------------\n",
    "    # Eliminate rows that have a \"findings\" wordcount larger than 100 words. \n",
    "    df[\"Number of Words\"] = df[\"Caption\"].apply(lambda n: len(n.split()))\n",
    "    df=df.loc[df['Number of Words']<=100]\n",
    "\n",
    "    # CLEANING ON THE \"ANATOMY\" COLUMN--------------------------\n",
    "    # Consolidation\n",
    "    df.Anatomy.replace('Brain and Neuro','Brain',inplace=True)\n",
    "    df.Anatomy.replace('Nerve, central','Brain',inplace=True)\n",
    "\n",
    "    df.Anatomy.replace('MSK - Musculoskeletal','Musculoskeletal',inplace=True)\n",
    "    df.Anatomy.replace('Extremity - Please Select MSK','Musculoskeletal',inplace=True)\n",
    "\n",
    "    df.Anatomy.replace('Chest, Pulmonary (ex. Heart)','Pulmonary',inplace=True)\n",
    "\n",
    "    df.Anatomy.replace('Breast and Mammography','Breast',inplace=True)\n",
    "\n",
    "    df.Anatomy.replace('Abdomen - Generalized','Abdomen',inplace=True)\n",
    "    df.Anatomy.replace('Gastrointestinal','Abdomen',inplace=True)\n",
    "\n",
    "    df.Anatomy.replace('Head and Neck (ex. orbit)','Head and Neck',inplace=True)\n",
    "    df.Anatomy.replace('Eye and Orbit (exclude Ophthalmology)','Head and Neck',inplace=True)\n",
    "\n",
    "    df.Anatomy.replace('Vascular','Cardiovascular',inplace=True)\n",
    "    df.Anatomy.replace('Cardiovascular (inc. Heart)','Cardiovascular',inplace=True)\n",
    "\n",
    "    df.Anatomy.replace('Multisystem','Generalized',inplace=True)\n",
    "\n",
    "    # Keep rows that have Anatomy values with a frequency higher than 200\n",
    "    valid_index=df.Anatomy.value_counts().index[df.Anatomy.value_counts()>200]\n",
    "    df=df.loc[df.Anatomy.isin(valid_index)]\n",
    "\n",
    "    # CLEANING THE IMPRESSIONS COLUMN---------------------\n",
    "    # Keep impressions with at most 30 words.\n",
    "    df[\"Number of Words\"] = df[\"Impression\"].apply(lambda n: len(n.split()))\n",
    "    df=df.loc[df['Number of Words']<=30]\n",
    "\n",
    "    # Eliminate the Number of words column\n",
    "    df.drop(columns='Number of Words').count()\n",
    "\n",
    "    # CONVERT THE PATH COLUMN INTO THE COMPLETE PATHS--------------------\n",
    "    prefix = '../data/raw/medpix/Images/'\n",
    "    suffix = '.jpg'\n",
    "    df.Path = prefix+df.Path.astype(str)+suffix\n",
    "\n",
    "    # CREATE THE FULL CAPTIONS COLUMN-------------------------------------\n",
    "    df['Full_Caption']=df.apply(lambda row: ('<start>'+\n",
    "                                             ' Core Modality: '+ str(row['Core_Modality'])+\n",
    "                                             ' Modality: ' + str(row['Modality'])+\n",
    "                                             ' Plane: ' + str (row['Plane']) +\n",
    "                                             ' Anatomy: ' + str(row['Anatomy'])+\n",
    "                                             ' Findings: '+ str(row['Caption'])+\n",
    "                                             #' Impression: '+ str(row['Impression'])+\n",
    "                                             ' <end>') ,axis=1)\n",
    "\n",
    "#      # SPLIT DATA IN TRAIN, VALIDATION AND TEST----------------------------------\n",
    "#     cases=list(df.Case_URL.unique()) # Make a list of medical cases\n",
    "#     # Shuffle the list\n",
    "#     random.seed(1)\n",
    "#     random.shuffle(cases)\n",
    "\n",
    "#     # Build the test and validation set with 10% of cases\n",
    "#     cases=list(df.Case_URL.unique()) # Make a list of medical cases\n",
    "#     # Shuffle the list\n",
    "#     random.seed(1)\n",
    "#     random.shuffle(cases)\n",
    "\n",
    "#     # Build the test and validation set with 10% of cases\n",
    "#     test_idx=int(len(cases)*0.05)\n",
    "#     val_idx=test_idx+int(len(cases)*0.05)\n",
    "\n",
    "#     test_cases = cases[0:test_idx] # list of test cases\n",
    "#     val_cases = cases[test_idx:val_idx] # list of validation cases\n",
    "#     train_cases = cases[val_idx:] # list of training cases\n",
    "\n",
    "#     df.loc[df.Case_URL.isin(test_cases),'Split']='test'\n",
    "#     df.loc[df.Case_URL.isin(val_cases),'Split']='validation'\n",
    "#     df.loc[df.Case_URL.isin(train_cases),'Split']='train'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "654e7ec3-a7d9-425b-97cd-1e1757e54e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA IN STRATIFIED TRAIN, VALIDATION AND TEST --------------------------\n",
    "# Choose stratified test set\n",
    "test_cases=[]\n",
    "for modality in df.Core_Modality.unique():\n",
    "# For every modality in the dataframe\n",
    "    sub_df=df.loc[df.Core_Modality==modality] # Get a df with this modality\n",
    "     # Get a list of unique cases with this modality. \n",
    "    available_cases=list(sub_df.Case_URL.unique())\n",
    "    chosen_cases= random.sample(available_cases,5) # Choose 5 cases at random.\n",
    "    test_cases+=chosen_cases # Append chosen cases to test_cases. \n",
    "    \n",
    "# Add test label to all rows corresponding to the chosen test cases. \n",
    "df.loc[df.Case_URL.isin(test_cases),'Split']='test'\n",
    "\n",
    "# Choose stratified validation set from remianing data. \n",
    "val_cases=[]\n",
    "for modality in df.Core_Modality.unique():\n",
    "# For every modality in the dataframe. \n",
    "    # Make a subdataframe with rows corresponding to this modality and e\n",
    "    # excluding rows already labeled as 'test'\n",
    "    sub_df=df.loc[(df.Core_Modality==modality)\n",
    "                  & (df['Split']!='test')]\n",
    "    available_cases=list(sub_df.Case_URL.unique())\n",
    "    chosen_cases= random.sample(available_cases,5)\n",
    "    val_cases+=chosen_cases\n",
    "\n",
    "# Select the validation df and exclude the validation cases from the rest of \n",
    "# the data. \n",
    "df.loc[df.Case_URL.isin(val_cases),'Split']='validation'\n",
    "# Label rows that are not 'test' or 'validation' as 'train'\n",
    "df.loc[~df.Split.isin(['test','validation']),'Split']='train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2c942a82-2baf-4f2e-b93d-0ce51f43a40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train         28071\n",
       "validation      324\n",
       "test            296\n",
       "Name: Split, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be654e1f-7e4d-41f7-81e5-7f4162e1b304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e8e2a8e-1fd2-44ef-ae7c-7cf4dd91579b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "49ad545e-d2b8-4e48-91d1-624998efc42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://medpix.nlm.nih.gov/bycase?id=00784aff-ae01-4ede-92c1-09f7df5a5bba',\n",
       " 'https://medpix.nlm.nih.gov/bycase?id=a90f0bba-7414-41eb-ab2d-cc2e52de46d3',\n",
       " 'https://medpix.nlm.nih.gov/bycase?id=753514a0-a130-4968-9ae5-0f98939ed681',\n",
       " 'https://medpix.nlm.nih.gov/bycase?id=b62c4b59-b4fe-4028-8135-c45e8b074ed9',\n",
       " 'https://medpix.nlm.nih.gov/bycase?id=f4c98eeb-f7da-45d6-9c3b-e51527c0a86e']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e9cfbd68-8581-4d08-899b-891140a9cab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_URL</th>\n",
       "      <th>Path</th>\n",
       "      <th>Plane</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Impression</th>\n",
       "      <th>Anatomy</th>\n",
       "      <th>Number of Words</th>\n",
       "      <th>Full_Caption</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Core_Modality</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AN</th>\n",
       "      <td>295</td>\n",
       "      <td>295</td>\n",
       "      <td>295</td>\n",
       "      <td>295</td>\n",
       "      <td>295</td>\n",
       "      <td>295</td>\n",
       "      <td>295</td>\n",
       "      <td>295</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS</th>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT</th>\n",
       "      <td>2484</td>\n",
       "      <td>2484</td>\n",
       "      <td>2484</td>\n",
       "      <td>2484</td>\n",
       "      <td>2484</td>\n",
       "      <td>2484</td>\n",
       "      <td>2484</td>\n",
       "      <td>2484</td>\n",
       "      <td>2484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GR</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HE</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INT</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MR</th>\n",
       "      <td>1925</td>\n",
       "      <td>1925</td>\n",
       "      <td>1925</td>\n",
       "      <td>1925</td>\n",
       "      <td>1925</td>\n",
       "      <td>1925</td>\n",
       "      <td>1925</td>\n",
       "      <td>1925</td>\n",
       "      <td>1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PET/NM</th>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UGI</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XR</th>\n",
       "      <td>1856</td>\n",
       "      <td>1856</td>\n",
       "      <td>1856</td>\n",
       "      <td>1856</td>\n",
       "      <td>1856</td>\n",
       "      <td>1856</td>\n",
       "      <td>1856</td>\n",
       "      <td>1856</td>\n",
       "      <td>1856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Case_URL  Path  Plane  Modality  Caption  Impression  Anatomy  \\\n",
       "Core_Modality                                                                  \n",
       "AN                  295   295    295       295      295         295      295   \n",
       "BAS                  81    81     81        81       81          81       81   \n",
       "CT                 2484  2484   2484      2484     2484        2484     2484   \n",
       "GR                   44    44     44        44       44          44       44   \n",
       "HE                   41    41     41        41       41          41       41   \n",
       "INT                  56    56     56        56       56          56       56   \n",
       "MR                 1925  1925   1925      1925     1925        1925     1925   \n",
       "PET/NM              206   206    206       206      206         206      206   \n",
       "UGI                  77    77     77        77       77          77       77   \n",
       "US                  519   519    519       519      519         519      519   \n",
       "XR                 1856  1856   1856      1856     1856        1856     1856   \n",
       "\n",
       "               Number of Words  Full_Caption  \n",
       "Core_Modality                                 \n",
       "AN                         295           295  \n",
       "BAS                         81            81  \n",
       "CT                        2484          2484  \n",
       "GR                          44            44  \n",
       "HE                          41            41  \n",
       "INT                         56            56  \n",
       "MR                        1925          1925  \n",
       "PET/NM                     206           206  \n",
       "UGI                         77            77  \n",
       "US                         519           519  \n",
       "XR                        1856          1856  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cases=[]\n",
    "df.groupby(['Core_Modality','Case_URL']).count().reset_index().groupby('Core_Modality').count()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "myenv",
   "name": "tf2-gpu.2-8.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m102"
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
